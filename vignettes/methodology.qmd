---
title: "Introduction to seroincidence estimation"
vignette: >
  %\VignetteIndexEntry{Introduction to seroincidence estimation}
  %\VignetteEngine{quarto::html}
  %\VignetteEncoding{UTF-8}
---

\renewcommand{\vec}[1]{\mathbf{#1}}

# Overview

## Defining incidence

The **incidence rate** of a disease over a **specific time period** is 
the rate at which individuals in a population are *acquiring* the disease 
during that time period [@Noordzij2010diseasemeasures].

**Example:**
if ten people in a population of 1000 contract typhoid 
over a one month time period, 
then the incidence rate for that time period is 
*"10 new cases per 1000 persons per month"*.

---

More mathematically, 
the incidence rate *at a given time point* is 
the *derivative* (i.e., the current rate of change over time) 
of the expected cumulative count of infections per person at risk, 
at that time:

$$\frac{d}{dt} \mathbb{E}\left[\frac{C(t)}{n} \mid N(t) =n\right]$$

where $C(t)$ is the cumulative total number of infections in the population of interest,
and $N(t)$ is the number of individuals at risk at time $t$.

---

## Scale of incidence rates

In both definitions, 
the units for an incidence rate are 
"# new infections per # persons at risk per time duration"; 
for example, "new infections per 1000 persons per year". 

For convenience, 
we can rescale the incidence rate to make it easier to understand; 
for example, we might express incidence as 
"# new infections per 1000 persons per year" 
or "# new infections per 100,000 persons per day", etc.

## Incidence from an individual's perspective

From the perspective of an individual in the population:

the **incidence rate** at a given time point ($t$)
is the instantaneous probability (density) of 
*becoming infected* at that time point,
*given* that they are *at risk* at that time point
(i.e., the *hazard rate*).

## Notation

We often use the greek letter $\lambda$ ("lambda") to denote the incidence rate.

# Estimating incidence from cross-sectional antibody surveys

## Cross-sectional antibody surveys {.incremental}

::: notes
Typically, it is difficult to estimate changes from a single time point. 
However, we can sometimes make assumptions that allow us to do so. 
In particular, if we assume that the incidence rate is constant over time, 
then we can estimate incidence from a single cross-sectional survey.

We will need two pieces of notation to formalize this process.

:::

::: incremental

* We recruit participants from the population of interest.

* For each survey participant, we measure antibody levels ($Y$) 
for the disease of interest

* Each participant had their most recent infection at some time duration ($T$)
*prior* to when we measured their antibodies.^[If they have never been infected, $T$ is infinite.]

* We can't directly observe $T$ - it is a "latent variable". 

* Instead, we only observe $Y$.

:::

## Time since infection and incidence

We assume that:

* the incidence rate is approximately constant 
**over time** and **across the population**:

$$\lambda_{i,t} = \lambda, \forall i,t$$

::: notes
(We can analyze subpopulations separately to make homogeneity more plausible.)
:::

* Participants are always at risk of a new infection

::: notes
(For diseases like typhoid, this assumption may not hold exactly,
but hopefully approximately; 
modeling the effects of re-exposure during an active infection is [on our to-do list](https://github.com/UCD-SERG/dcm/issues/11)).
:::

Then $T$ has an exponential distribution 
whose rate parameter is the incidence rate:

$$p(T=t) = \lambda \exp(-\lambda t)$$

::: notes
That is, the probability that 
an individual was **last** infected $t$ days ago, $p(T=t)$, 
is equal to the probability of being infected at time $t$ 
(i.e., the incidence rate at time $t$, $\lambda$) 
times the probability of not being infected after time $t$, 
which turns out to be $\exp(-\lambda t)$.
:::


## Likelihood for observed infection times

If we could observe $T$, we could compute the likelihood of the data:

$$
\begin{aligned}
\mathcal{L}^*(\lambda)
&= \prod_{i=1}^n p(T=t_i)
\\ &= \prod_{i=1}^n \lambda \exp(-\lambda t_i)\\
\end{aligned}
$$

::: notes
Then we could estimate $\lambda$ by maximizing this likelihood.^[by taking the logarithm of the likelihood, taking the derivative of that "log-likelihood", setting it equal to 0, and solving for $\lambda$.]
:::

## Example log-likelihood curves

```{r}
#| fig-cap: "Example log-likelihood curves"
#| label: fig-ex-lik-curves

library(serocalculator)
library(dplyr)
# Import longitudinal antibody parameters from OSF
curves <-
  "https://osf.io/download/rtw5k/" %>%
  load_curve_params() %>%
  filter(iter < 50)

# Import cross-sectional data from OSF and rename required variables:
xs_data <-
  "https://osf.io/download//n6cp3/" %>%
  load_pop_data()

noise <- url("https://osf.io/download//hqy4v/") %>% readRDS()
```

```{r}
#| fig-cap: "Example log(likelihood) curves"
#| label: fig-loglik
lik_HlyE_IgA <- graph.loglik(
  pop_data = xs_data,
  curve_params = curves,
  noise_params = noise,
  antigen_isos = "HlyE_IgA",
  log_x = TRUE
)

lik_HlyE_IgG <- graph.loglik(
  previous_plot = lik_HlyE_IgA,
  pop_data = xs_data,
  curve_params = curves,
  noise_params = noise,
  antigen_isos = "HlyE_IgG",
  log_x = TRUE
)

lik_both <- graph.loglik(
  previous_plot = lik_HlyE_IgG,
  pop_data = xs_data,
  curve_params = curves,
  noise_params = noise,
  antigen_isos = c("HlyE_IgG", "HlyE_IgA"),
  log_x = TRUE
)

print(lik_both)
```

## standard error

The standard error of the estimate is approximately equal to the inverse of the rate of curvature (2nd derivative, aka Hessian) in the log-likelihood function, at the maximum:

more curvature -> likelihood peak is clearer -> smaller standard errors

## The plot thickens

Unfortunately, we don't observe infection times $T$; we only observe antibody levels ${Y}$. So things get a little more complicated.

In short, we are hoping that we can estimate $T$ (time since last infection) from $Y$ (current antibody levels). If we could do that, then we could plug in our estimates $\hat t_i$ into that likelihood above, and estimate $\lambda$ as previously.

We're actually going to do something a little more nuanced; instead of just using one value for $\hat t$, we are going to consider all possible values of $t$ for each individual.

## Likelihood of observed data

The likelihood of our individual's observed data, $P(Y=y)$, can be expressed as an integral over the joint probability of $Y$ and $T$ (using the Law of Total Probability):

$$
\begin{aligned}
p(Y=y) 
&= \int_t p(Y=y,T=t)dt
\end{aligned}
$$

---

Further, we can express the joint probability $p(Y=y,T=t)$ as the product of $p(T=t)$ and 
$p(Y=y|T=t)$ the "antibody response curve after infection". That is:

$$
p(Y=y,T=t) = p(Y=y|T=t)P(T=t)
$$

## Antibody response decay curves

::: {#fig-decay}

![](fig/fig1a-1.svg)

Antibody response decay curves, $p(Y=y|T=t)$, for typhoid

:::

## Putting it all together

Substituting $p(Y=y,T=t) = p(Y=y|T=t)P(T=t)$ into the previous expression for $p(Y=y)$:

$$
\begin{aligned}
p(Y=y)
&= \int_t p(Y=y|T=t)P(T=t) dt
\end{aligned}
$$

## Composing the likelihood {.smaller}

Now, the likelihood of the observed data $\vec{y} = (y_1, y_2, ..., y_n)$ is:

$$
\begin{aligned}
\mathcal{L}(\lambda) 
&= \prod_{i=1}^n p(Y=y_i)
\\&= \prod_{i=1}^n \int_t p(Y=y_i|T=t)p_\lambda(T=t)dt\\
\end{aligned}
$$

If we know $p(Y=y|T=t)$, then we can maximize $\mathcal{L}(\lambda)$ over $\lambda$ to find the "maximum likelihood estimate" (MLE) of $\lambda$, denoted $\hat\lambda$.

## Finding the MLE numerically

The likelihood of $Y$ involves the product of integrals, so the log-likelihood involves the sum of the logs of integrals:

$$
\begin{aligned}
\log \mathcal{L} (\lambda) 
&= \log \prod_{i=1}^n \int_t p(Y=y_i|T=t)p_\lambda(T=t)dt\\
&= \sum_{i=1}^n \log\left\{\int_t p(Y=y_i|T=t)p_\lambda(T=t)dt\right\}\\
\end{aligned}
$$

::: notes

The derivative of this expression doesn't come out cleanly, so we will use a *numerical method* (specifically, a Newton-type algorithm, implemented by `stats::nlm()`) to find the MLE and corresponding standard error.

:::

# Modeling the seroresponse kinetics curve

## A simple model for the seroresponse {.smaller}

Now, the big problem becomes modeling $p(Y=y|T=t)$.

The current version of the serocalculator package uses the model proposed in @Teunis_2016 for 
the shape of the seroresponse:

$$
\begin{array}{ll}
\text{Infection/colonization episode} & \text{Waning immunity episode}\\
b^{\prime}(t) = \mu_{0}b(t) - cy(t) & b(t) = 0 \\
y^{\prime}(t) = \mu y(t) & y^{\prime}(t) = -\alpha y(t)^r \\
\end{array}
$$

With baseline antibody concentration $y(0) = y_{0}$ and initial pathogen concentration 
$b(0) = b_{0}$. 

---

The serum antibody response $y(t)$ can be written as

$$
y(t) = y_{+}(t) + y_{-}(t)
$$

where

$$
\begin{align}
y_{+}(t) & = y_{0}\text{e}^{\mu t}[0\le t <t_{1}]\\
y_{-}(t) & = y_{1}\left(1+(r-1)y_{1}^{r-1}\alpha(t-t_{1})\right)^{-\frac{1}{r-1}}[t_{1}\le t < \infty]
\end{align}
$$

---

Since the peak level is $y_{1} = y_{0}\text{e}^{\mu t_{1}}$ 
the growth rate $\mu$ can be written as 
$$\mu = \frac{1}{t_{1}}\log\left(\frac{y_{1}}{y_{0}}\right)$$

---

```{r}
cur_ai = "HlyE_IgG"
```

```{r}
#| label: fig-response-graph
#| fig-cap: An example kinetics curve for `r cur_ai`
curve1 = 
  curves %>% 
  filter(
    # iter %in% 1:10,
    iter == 5,
         antigen_iso == cur_ai)

library(ggplot2)

curve1 %>% 
serocalculator:::plot_curve_params_one_ab(
  log_y = FALSE
) +
  xlim(0, 100) +
  theme_minimal() +
  geom_vline(
    aes(xintercept = curve1$t1,
        col = "t1")
  ) +
  
  geom_hline(
    aes(yintercept = curve1$y0,
        col = "y0")
  ) +
  
  
  geom_hline(
    aes(yintercept = curve1$y1,
        col = "y1")
  ) +
  # geom_point(
  #   data = curve1,
  #   aes(
  #     x = t1,
  #     y = y1,
  #     col = "(t1,y1)"
  #   )
  # ) + 
  theme(legend.position = "bottom") +
  labs(col = "")

```


:::: notes
The antibody level at $t=0$ is $y_{0}$; 
the rising branch ends at $t = t_{1}$ 
where the peak antibody level $y_{1}$ is reached. 
Any antibody level $y(t) \in (y_{0}, y_{1})$ eventually occurs twice.
::::

---

Antibody decay is different from exponential (log--linear) decay. When the shape parameter $r > 1$, 
log concentrations decrease rapidly after infection has terminated, 
but decay then slows down and 
low antibody concentrations are maintained for a long period. 
When $r$ approaches 1, exponential 
decay is restored.


## Biological noise

When we measure antibody concentrations in a blood sample, we are essentially counting molecules (using biochemistry).

We might miss some of the antibodies (undercount, false negatives) and we also might incorrectly count some other molecules that aren't actually the ones we are looking for (overcount, false positives, cross-reactivity).

We are more concerned about overcount (cross-reactivity) than undercount. For a given antibody, we can do some analytical work beforehand to estimate the distribution of overcounts, and add that to our model $p(Y=y|T=t)$.

## Measurement noise

There are also some other sources of noise in our bioassays; user differences in pipetting technique, random ELISA plate effects, etc. This noise can cause both overcount and undercount. We can also estimate the magnitude of this noise source, and include it in $p(Y=y|T=t)$.

<!-- {{< include methods-continued.qmd >}} -->

---

# References
